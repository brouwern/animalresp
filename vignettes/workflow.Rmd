---
title: "Cleaning Respiration Data Workflow"
author: "Brian Trevelline and Nathan Brouwer"
date: "May 7, 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

This scipt contains a workflow for importing data from respiration measurements from XXXXXX, processing, and summarizing the data.

Key steps in the workflow are

*

## Preliminaries

### Load Libraries

```{r}
#Load libraries
library(ggplot2) #plotting
library(cowplot) #nice ggplot defaults
library(dplyr)
library(readr)
library(plyr)

library(reshape2) #reshape data to calcualte minimum
library(doBy)


```


### Source custom R functions

Load the 3 functions used

* read_csv_append_filename(): loads a raw data file and appends file name
* clean_resp_dat(): cleans respirtation data
* code_flushes(): codes "flush" periods versus data capture time periods

Functions are in /R folder

```{r}
source('./R/read_csv_append_filename.R') #loads a raw data file and appends file name
source('./R/clean_and_resave_resp_dat.R') # cleans raw respiration data
source('./R/clean_and_resave_multi_dat.R')

source('~/1_R/git/animalresp/R/code_resp_dat.R')
#source('./R/code_flushes.R') #codes "flush" periods vs. data collection periods

```



## Workflow

### Clean data

This removes formatting from the instrument and makes other minor changes

Get all file names associated with an experiment.
```{r}
rawdata_filepaths <- list.files(path = "./data-raw/",
                                pattern = ".csv",
                        full.names = TRUE, 
                        ignore.case = TRUE)

```


Clean data and re-save to data-clean directory
```{r}
# clean a single file
clean_and_resave_resp_dat(rawdata_filepaths[1],object_name = NULL)

# clean all in a directory files
clean_and_resave_multi_dat(rawdata_filepaths, verbose = FALSE)

```


Get names of cleaned data
```{r}
cleandata_filepaths <- list.files(path = "./data-cleaned/", 
                        full.names = TRUE, 
                        ignore.case = TRUE)

```



### Code data

Determine all relevant info about each data point

* which chamber it was collected from
* whether it was part of initial flush for is a valid measurement

#### Code a single study
```{r}
temp <- code_resp_dat(dat = cleandata_filepaths[1])


summary(temp[,c("i.row","pass.rep.i","chamber","cycle.number","pass.i","measure.type")])


# Visualize data collect
ggplot(data = temp,
       aes(y = pass.rep.i, 
           x = i.row, 
           color = factor(chamber),
           shape = factor(cycle.number))) +
  geom_point() +
  xlab("Measurements in sequentical order") +
  ylab("Replicate measurement w/in a pass ") +
  geom_hline(yintercept = 19)




ggplot(data = temp,
       aes(y = pass.i, 
           x = i.row, 
           color = factor(channel),
           shape = factor(cycle.number))) +
  geom_point() +
  xlab("Measurements in sequentical order") +
  ylab("Replicate measurement w/in a pass ") +
  geom_hline(yintercept = 19)




head(temp[,c("channel","chamber")])
tail(temp[,c("channel","chamber")])

with(temp,all(channel == chamber))
```

#### Code all studies in a directory

```{r}
#assign names to vector of files names
## so that they get passed to list of processed data
names(cleandata_filepaths) <- cleandata_filepaths

coded.data.list <- llply(cleandata_filepaths, code_resp_dat)

names(coded.data.list)
length(coded.data.list)
```




### Load Metadata file

```{r}
az.metadata <- read.csv("./metadata/AZ_metadata.csv")
```

### Merge Data

```{r}
# use do.call() to stack all seperate files
merged.data <- do.call(rbind, coded.data.list)
row.names(coded.data.list) <- NULL

# ?? create source-file-channle ID
### source file plus channel number
merged.data$SourceFileChannel <- paste(merged.data$SourceFile, 
                                       merged.data$channel) #LatestChannel? Latest = ?


# use match() to cross reference meta data and data
merged.data$ID <- az.metadata$ID[match(merged.data$SourceFileChannel, 
                                       az.metadata$SourceFileChannel)]

merged.data$Mass <- az.metadata$Mass[match(merged.data$SourceFileChannel, 
                                      az.metadata$SourceFileChannel)]

merged.data$Cumulative <- az.metadata$CumulativeChannelNumber[match(merged.data$SourceFileChannel, az.metadata$SourceFileChannel)]

# save merged data
## saved in subfolder /data-merged
write.csv(merged.data, "./data-merged/AZ-merged.csv")
```


## Worflow
## Plot data

```{r}
ggplot(data = merged.data,
       aes(y = Q.S102.O2.Pcor ,
           x = pass.rep.i,
           group = cycle.number,
           color= factor(cycle.number),
           shape = measure.type)) + 
  geom_point() +
  geom_line() +
  facet_wrap(~ID) +
  geom_vline(xintercept = 19)
```


## Calculate minimum

### Global minimum

Lowest value for a each mouse accross all cycles
```{r}
global.min <- dcast(data = merged.data,
      formula = ID ~ .,
      value.var = "Q.S102.O2.Pcor",
      fun.aggregate = min)

names(global.min)[2] <- "min"
```


### Minimum by Phase

```{r}
phase.min <- dcast(data = merged.data,
      formula = ID ~ measure.type,
      value.var = "Q.S102.O2.Pcor",
      fun.aggregate = min)

```


### Variance by Phase

```{r}
phase.var <- dcast(data = my_phys_coded,
      formula = channel ~ phase,
      value.var = "Q.S102.O2.Pcor",
      fun.aggregate = var)

```


```{r}
summary_AZ_23_APR<- summaryBy(Q.S102.O2.Pcor ~ channel, data = my_phys_coded, FUN = c(min,max,mean,sd,var))
write.csv(summary_AZ_23_APR, file = './summaries/summary_AZ_23_APR.csv' )
```

